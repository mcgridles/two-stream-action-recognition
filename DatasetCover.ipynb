{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import dataloader\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from time import time\n",
    "\n",
    "from scipy.special import softmax \n",
    "\n",
    "from action_utils import *\n",
    "from two_stream_loader import *\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial Dataloader Initialized\n",
      "==> (Training video, Validation video):( 899 183 )\n",
      "==> sampling testing frames\n",
      "Spatial train Dataset Initialized\n",
      "==> Training data : 899 frames\n",
      "Spatial val Dataset Initialized\n",
      "==> Validation data : 3477 frames\n"
     ]
    }
   ],
   "source": [
    "dataloader = dataloader.spatial_dataloader(BATCH_SIZE=1, num_workers=1, \n",
    "                                           path='/mnt/disks/datastorage/videos/old/rgb_2/', \n",
    "                                           ucf_list='/home/mlp/two-stream-action-recognition/UCF_list/',\n",
    "                                           ucf_split='01')\n",
    "train_loader,val_loader,test_video = dataloader.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count = dataloader.frame_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_training = dataloader.dic_training.copy()\n",
    "\n",
    "dic_testing = {}\n",
    "for key,value in test_video.items():\n",
    "    dic_testing[key+\" \"+str(frame_count[key]-10+1)] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_training.update(dic_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_spatial = r\"/mnt/disks/datastorage/videos/old/rgb_2/\"\n",
    "\n",
    "j = 0\n",
    "entire_logo = np.zeros((64,1792,3))\n",
    "for j,(key,value) in enumerate(dic_training.items()):\n",
    "    video_name,nb_frames = key.split(' ')\n",
    "    nb_frames = int(nb_frames)\n",
    "    frame = os.listdir(path_spatial+\"v_\"+video_name)[idx]\n",
    "    start_logo_row = cv2.resize(cv2.imread(path_spatial+\"v_\"+video_name+\"/\"+frame),(64,64))\n",
    "    \n",
    "    for i in range(27):\n",
    "        video_name,nb_frames = np.random.choice(list(dic_training.keys()),(1))[0].split(' ')\n",
    "        nb_frames = int(nb_frames)\n",
    "        idx = np.random.randint(1,nb_frames)\n",
    "        frame = os.listdir(path_spatial+\"v_\"+video_name)[idx]\n",
    "        img1 = cv2.resize(cv2.imread(path_spatial+\"v_\"+video_name+\"/\"+frame),(64,64))\n",
    "        start_logo_row = np.hstack((start_logo_row,img1))\n",
    "    \n",
    "    entire_logo = np.vstack((entire_logo,start_logo_row))\n",
    "    if j == 8:\n",
    "        break\n",
    "final_logo = entire_logo[64:-1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"LENS\"\n",
    "logo = cv2.putText(\n",
    "        final_logo,\n",
    "        label,\n",
    "        (int(final_logo.shape[1]/2)-200,int(final_logo.shape[0]/2)+50),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        5,\n",
    "        (255, 255, 255),\n",
    "        thickness=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,40))\n",
    "plt.imshow(logo/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make gif to make noah happy boy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_spatial = r\"/mnt/disks/datastorage/videos/old/rgb_2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "frame_len = 60\n",
    "vids = np.array([video.split(\" \")[0] for video in list(dic_training.keys())])\n",
    "vids = np.random.choice(vids,[1,28*7])\n",
    "\n",
    "out = cv2.VideoWriter(\"logo.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 20.0, (1792,449), True)\n",
    " \n",
    "entire_logo = np.zeros((64,1792,3))\n",
    "label = \"LENS\"\n",
    "for frame in range(frame_len):\n",
    "    print(frame)\n",
    "    frame = str(frame+1)\n",
    "    frame = \"frame\"+\"0\"*(6-len(frame)) + frame + \".jpg\"\n",
    "    frame_list = []\n",
    "    \n",
    "    for j,vid in enumerate(vids.tolist()[0]):\n",
    "        im = cv2.resize(cv2.imread(path_spatial+\"v_\"+vid+\"/\"+frame),(64,64))\n",
    "        frame_list.append(im)\n",
    "        \n",
    "    a = np.hstack(frame_list)\n",
    "    c = np.zeros((1,28*64,3))\n",
    "    for k in range(7):\n",
    "        b= a[0:64,(k*28*64):((28*64)*(k+1))]\n",
    "        c = np.vstack((c,b))    \n",
    "\n",
    "    logo = cv2.putText(\n",
    "            c,\n",
    "            label,\n",
    "            (int(c.shape[1]/2)-250,int(c.shape[0]/2)+50),\n",
    "            cv2.FONT_HERSHEY_TRIPLEX,\n",
    "            5,\n",
    "            (255, 255, 255),\n",
    "            thickness=10\n",
    "        )\n",
    "\n",
    "    logo = np.uint8(logo)\n",
    "    out.write(logo)\n",
    "\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
